# Spark Scala Workshop

Simple Spark with Scala introductory workshop.

This repo is intended to serve as a _"one-oh-one"_ (101) introductory workshop for Spark with Scala.  
I will cover basic aspects of Spark, especially:

  + Spark Execution Model.
  + Resilient Distributed Datasets _(**RDDs**)_.
  + Transformations _(lazy)_ vs Actions _(eager)_.
  + Partitions and Shuffling.
  + DataFrames & Datasets.

## Prerequisites

For this workshop you only need:

  1. A _fork_ of this _repo_.
  2. A [Java Development Kit _(**JDK**)_ 8](https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html) on your classpath.
  3. The [Scala Build Tool _(**SBT**)_](https://www.scala-sbt.org/1.x/docs/Setup.html) installed.
  4. An IDE of your preference.
